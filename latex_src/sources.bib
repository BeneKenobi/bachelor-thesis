@article{Behjati2013,
  title = {What Is next Generation Sequencing?},
  author = {Behjati, Sam and Tarpey, Patrick S.},
  year = {2013},
  month = aug,
  journal = {Archives of Disease in Childhood - Education and Practice},
  volume = {98},
  number = {6},
  pages = {236--238},
  publisher = {{BMJ}},
  doi = {10.1136/archdischild-2013-304340},
}

@article{Collins2003,
  title = {The {{Human Genome Project}}: {{Lessons}} from {{Large-Scale Biology}}},
  shorttitle = {The {{Human Genome Project}}},
  author = {Collins, Francis S. and Morgan, Michael and Patrinos, Aristides},
  date = {2003-04-11},
  journaltitle = {Science},
  volume = {300},
  number = {5617},
  pages = {286--290},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1084564},
  abstract = {The Human Genome Project has been the first major foray of the biological and medical research communities into “big science.” In this Viewpoint, we present some of our experiences in organizing and managing such a complicated, publicly funded, international effort. We believe that many of the lessons we learned will be applicable to future large-scale projects in biology.}
}

@article{Lilue2018,
  title = {Sixteen Diverse Laboratory Mouse Reference Genomes Define Strain-Specific Haplotypes and Novel Functional Loci},
  author = {Lilue, Jingtao and Doran, Anthony G. and Fiddes, Ian T. and Abrudan, Monica and Armstrong, Joel and Bennett, Ruth and Chow, William and Collins, Joanna and Collins, Stephan and Czechanski, Anne and Danecek, Petr and Diekhans, Mark and Dolle, Dirk-Dominik and Dunn, Matt and Durbin, Richard and Earl, Dent and Ferguson-Smith, Anne and Flicek, Paul and Flint, Jonathan and Frankish, Adam and Fu, Beiyuan and Gerstein, Mark and Gilbert, James and Goodstadt, Leo and Harrow, Jennifer and Howe, Kerstin and Ibarra-Soria, Ximena and Kolmogorov, Mikhail and Lelliott, Chris J. and Logan, Darren W. and Loveland, Jane and Mathews, Clayton E. and Mott, Richard and Muir, Paul and Nachtweide, Stefanie and Navarro, Fabio C. P. and Odom, Duncan T. and Park, Naomi and Pelan, Sarah and Pham, Son K. and Quail, Mike and Reinholdt, Laura and Romoth, Lars and Shirley, Lesley and Sisu, Cristina and Sjoberg-Herrera, Marcela and Stanke, Mario and Steward, Charles and Thomas, Mark and Threadgold, Glen and Thybert, David and Torrance, James and Wong, Kim and Wood, Jonathan and Yalcin, Binnaz and Yang, Fengtang and Adams, David J. and Paten, Benedict and Keane, Thomas M.},
  date = {2018-11},
  journaltitle = {Nature Genetics},
  shortjournal = {Nat Genet},
  volume = {50},
  number = {11},
  pages = {1574--1583},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1718},
  doi = {10.1038/s41588-018-0223-8},
  abstract = {We report full-length draft de novo genome assemblies for 16 widely used inbred mouse strains and find extensive strain-specific haplotype variation. We identify and characterize 2,567 regions on the current mouse reference genome exhibiting the greatest sequence diversity. These regions are enriched for genes involved in pathogen defence and immunity and exhibit enrichment of transposable elements and signatures of recent retrotransposition events. Combinations of alleles and genes unique to an individual strain are commonly observed at these loci, reflecting distinct strain phenotypes. We used these genomes to improve the mouse reference genome, resulting in the completion of 10 new gene structures. Also, 62 new coding loci were added to the reference genome annotation. These genomes identified a large, previously unannotated, gene (Efcab3-like) encoding 5,874 amino acids. Mutant Efcab3-like mice display anomalies in multiple brain regions, suggesting a possible role for this gene in the regulation of brain development.},
  issue = {11}
}

@article{Morrell2012,
  title = {Crop Genomics: Advances and Applications},
  shorttitle = {Crop Genomics},
  author = {Morrell, Peter L. and Buckler, Edward S. and Ross-Ibarra, Jeffrey},
  date = {2012-02},
  journaltitle = {Nature Reviews Genetics},
  shortjournal = {Nat Rev Genet},
  volume = {13},
  number = {2},
  pages = {85--96},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3097},
  abstract = {Reference genome sequences from many important crops and several model plant species are enabling a number of new applications of crop comparative genomics.Compared with previous methods, comparative resequencing and high-density SNP genotyping permit much more detailed examination of crop evolutionary history and improve the potential to identify loci that are involved in plant domestication and improvement.Genome-wide association studies and a new generation of genetic-mapping populations will improve assessment of the genetic basis of trait variation.Deleterious mutations in individual genomes can be identified and selected against or even repaired.Genomic selection or genome-wide marker-assisted selection can incorporate prior information on the effects of markers and accelerate plant breeding cycles.},
  issue = {2}
}

@article{Bamshad2011,
  title = {Exome {{Sequencing As}} a {{Tool}} for {{Mendelian Disease Gene Discovery}}},
  author = {Bamshad, Michael J. and Ng, Sarah B. and Bigham, Abigail W. and Tabor, Holly K. and Emond, Mary J. and Nickerson, Deborah A. and Shendure, Jay},
  year = {2011},
  month = sep,
  journal = {Nature Reviews Genetics},
  volume = {12},
  number = {11},
  pages = {745--755},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1038/nrg3031},
}

@article{VanEl2013,
  title = {Whole-Genome Sequencing in Health Care},
  author = {{van El}, Carla G. and Cornel, Martina C. and Borry, Pascal and Hastings, Ros J. and Fellmann, Florence and Hodgson, Shirley V. and Howard, Heidi C. and {Cambon-Thomsen}, Anne and Knoppers, Bartha M. and {Meijers-Heijboer}, Hanne and Scheffer, Hans and Tranebjaerg, Lisbeth and Dondorp, Wybo and {de Wert}, Guido M. W. R.},
  year = {2013},
  month = may,
  journal = {European Journal of Human Genetics},
  volume = {21},
  number = {6},
  pages = {580--584},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1038/ejhg.2013.46},
}

@online{NLM2009,
  title = {{{GRCh37}}},
  author = {{National Library of Medicine}},
  year = {2009},
  url = {https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.13/},
  urldate = {2022-05-18}
}

@online{NLM2013,
  title = {{{GRCh38}}},
  author = {{National Library of Medicine}},
  year = {2013},
  url = {https://www.ncbi.nlm.nih.gov/assembly/GCF_000001405.26/},
  urldate = {2022-05-18},
  }

@online{Patel2018,
  title = {Get to {{Know Your Reference Genome}} ({{GRCh37}} vs {{GRCh38}})},
  author = {Patel, Khushbu},
  year = {2018},
  month = apr,
  url = {https://bitesizebio.com/38335/get-to-know-your-reference-genome-grch37-vs-grch38/},
  urldate = {2022-06-22},
  abstract = {Whether your experiment relies upon a reference-based genome assembly or mapping reads to a reference genome to identify variants, you need to choose a human reference genome assembly. But wait! You go to the FTP site of NCBI's refseq and click on the Homo sapiens folder. There you are presented with two choices. Which one should you choose? GRCh37 or GRCh38? What differs between them? Are they just the same? Does it make a difference which you choose? To address these questions, let's talk about what are reference genomes: why do we need them, what are the distinctions among them, and finally how will they affect our results?},
  creationdate = {2022-06-22T08:54:10},
  langid = {american},
}

@online{Wetterstrand2021,
  title = {{{DNA Sequencing Costs}}: {{Data}} from the {{NHGRI Genome Sequencing Program}} ({{GSP}})},
  author = {Wetterstrand, Kris A.},
  year = {2021},
  url = {https://www.genome.gov/sequencingcostsdata},
  urldate = {2022-05-11},
}

@article{Li2009,
  title = {The {{Sequence Alignment}}/{{Map}} Format and {{SAMtools}}},
  author = {Li, H. and Handsaker, B. and Wysoker, A. and Fennell, T. and Ruan, J. and Homer, N. and Marth, G. and Abecasis, G. and Durbin, R. and {1000 Genome Project Data Processing Subgroup}},
  year = {2009},
  month = aug,
  journal = {Bioinformatics},
  volume = {25},
  number = {16},
  pages = {2078--2079},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btp352},
  langid = {english},
}


@article{Cock2009,
  title = {The {{Sanger FASTQ}} File Format for Sequences with Quality Scores, and the {{Solexa}}/{{Illumina FASTQ}} Variants},
  author = {Cock, Peter J. A. and Fields, Christopher J. and Goto, Naohisa and Heuer, Michael L. and Rice, Peter M.},
  year = {2009},
  month = dec,
  journal = {Nucleic Acids Research},
  volume = {38},
  number = {6},
  pages = {1767--1771},
  publisher = {{Oxford University Press (OUP)}},
  doi = {10.1093/nar/gkp1137},
}


@article{Danecek2021,
  title = {Twelve Years of {{SAMtools}} and {{BCFtools}}},
  author = {Danecek, Petr and Bonfield, James K. and Liddle, Jennifer and Marshall, John and Ohan, Valeriu and Pollard, Martin O. and Whitwham, Andrew and Keane, Thomas and McCarthy, Shane A. and Davies, Robert M. and Li, Heng},
  year = {2021},
  month = feb,
  journal = {GigaScience},
  volume = {10},
  number = {2},
  pages = {giab008},
  issn = {2047-217X},
  doi = {10.1093/gigascience/giab008},
  abstract = {BACKGROUND: SAMtools and BCFtools are widely used programs for processing and analysing high-throughput sequencing data. They include tools for file format conversion and manipulation, sorting, querying, statistics, variant calling, and effect analysis amongst other methods. FINDINGS: The first version appeared online 12 years ago and has been maintained and further developed ever since, with many new features and improvements added over the years. The SAMtools and BCFtools packages represent a unique collection of tools that have been used in numerous other software projects and countless genomic pipelines. CONCLUSION: Both SAMtools and BCFtools are freely available on GitHub under the permissive MIT licence, free for both non-commercial and commercial use. Both packages have been installed {$>$}1 million times via Bioconda. The source code and documentation are available from https://www.htslib.org.},
  langid = {english},
  pmcid = {PMC7931819},
  pmid = {33590861},
}


@software{BroadInstitute2019,
  title = {Picard Toolkit},
  author = {{Broad Institute}},
  date = {2019},
  url = {https://broadinstitute.github.io/picard/},
  urldate = {2022-09-16}
}

@online{Sturm2018,
  title = {Ngs-Bits {{Short-read}} Sequencing Tools for Diagnostics},
  author = {Sturm, Marc and Schroeder, Christopher and Matthes, Jakob and Ossowski, Stephan},
  year = {2018},
  url = {https://github.com/imgag/ngs-bits/blob/master/doc/data/poster_ECCB2018.pdf},
  urldate = {2022-09-16},
  abstract = {Over the last few years, next-generation-sequencing (NGS) continuously became more affordable and the data analysis tools for NGS became more and more mature. Thus, many molecular biology technologies traditionally used in medical genetics (e.g. Sanger sequencing and genome arrays) are widely replaced by NGS. There are well-established standard tools for the main analysis steps, e.g. BWA for mapping and GATK for variant calling of short-read DNA sequencing, that are readily usable in diagnostics. However, many of the auxiliary tools needed for a diagnostics NGS pipeline, e.g. those for quality control, are written rather for research than for diagnostics and are not as mature as they should be for diagnostics. They often lack in speed, documentation and/or ease-of-use. Additionally, they are distributed over many different projects and are based on different programming languages, which makes installation and regular updates very time-consuming.},
  langid = {english},
}

@article{Tischler2014,
  title = {Biobambam: Tools for Read Pair Collation Based Algorithms on {{BAM}} Files},
  shorttitle = {Biobambam},
  author = {Tischler, German and Leonard, Steven},
  year = {2014},
  month = jun,
  journal = {Source Code for Biology and Medicine},
  volume = {9},
  pages = {13},
  doi = {10.1186/1751-0473-9-13},
  abstract = {Background Sequence alignment data is often ordered by coordinate (id of the reference sequence plus position on the sequence where the fragment was mapped) when stored in BAM files, as this simplifies the extraction of variants between the mapped data and the reference or of variants within the mapped data. In this order paired reads are usually separated in the file, which complicates some other applications like duplicate marking or conversion to the FastQ format which require to access the full information of the pairs. Results In this paper we introduce biobambam, a set of tools based on the efficient collation of alignments in BAM files by read name. The employed collation algorithm avoids time and space consuming sorting of alignments by read name where this is possible without using more than a specified amount of main memory. Using this algorithm tasks like duplicate marking in BAM files and conversion of BAM files to the FastQ format can be performed very efficiently with limited resources. We also make the collation algorithm available in the form of an API for other projects. This API is part of the libmaus package. Conclusions In comparison with previous approaches to problems involving the collation of alignments by read name like the BAM to FastQ or duplication marking utilities our approach can often perform an equivalent task more efficiently in terms of the required main memory and run-time. Our BAM to FastQ conversion is faster than all widely known alternatives including Picard and bamUtil. Our duplicate marking is about as fast as the closest competitor bamUtil for small data sets and faster than all known alternatives on large and complex data sets.},
}

@online{Sturm2021,
  title = {{{GitHub}}: Merging {{GRCh38}} Branch into Master},
  author = {Sturm, Marc},
  year = {2021},
  url = {https://github.com/imgag/megSAP/pull/102},
  urldate = {2022-05-17},
}

@online{IlluminaInc.2022,
  title = {Illumina {{DRAGEN Bio-IT Platform}}},
  author = {{Illumina, Inc.}},
  year = {2022},
  url = {https://emea.illumina.com/products/by-type/informatics-products/dragen-bio-it-platform.html},
  urldate = {2022-05-16},
}

@online{AmazonWebServices2022,
  title = {Amazon {{EC2 F1-Instances}}},
  author = {{Amazon Web Services}},
  year = {2022},
  url = {https://aws.amazon.com/de/ec2/instance-types/f1/},
  urldate = {2022-05-17},
}

@incollection{Bem2003,
  title = {Writing the {{Empirical Journal Article}}},
  booktitle = {The {{Compleat Academic}}},
  author = {Bem, Daryl},
  editor = {Darley, J. M. and Zanna, M. P. and Roediger III, H. L.},
  year = {2003},
  pages = {171--201},
  publisher = {{Psychology Press}},
  address = {{Washington, DC}},
  doi = {10.4324/9781315808314-10},
}

@article{Gregor2013,
  title = {Positioning and {{Presenting Design Science Research}} for {{Maximum Impact}}},
  author = {Gregor, Shirley and Hevner, Alan R.},
  year = {2013},
  journal = {MIS Quarterly},
  volume = {37},
  number = {2},
  pages = {337--355},
  publisher = {{Management Information Systems Research Center, University of Minnesota}},
  issn = {02767783},
  doi = {10.25300/MISQ/2013/37.2.01},
  abstract = {Design science research (DSR) has staked its rightful ground as an important and legitimate Information Systems (IS) research paradigm. We contend that DSR has yet to attain its full potential impact on the development and use of information systems due to gaps in the understanding and application of DSR concepts and methods. This essay aims to help researchers (1) appreciate the levels of artifact abstractions that may be DSR contributions, (2) identify appropriate ways of consuming and producing knowledge when they are preparing journal articles or other scholarly works, (3) understand and position the knowledge contributions of their research projects, and (4) structure a DSR article so that it emphasizes significant contributions to the knowledge base. Our focal contribution is the DSR knowledge contribution framework with two dimensions based on the existing state of knowledge in both the problem and solution domains for the research opportunity under study. In addition, we propose a DSR communication schema with similarities to more conventional publication patterns, but which substitutes the description of the DSR artifact in place of a traditional results section. We evaluate the DSR contribution framework and the DSR communication schema via examinations of DSR exemplar publications.},
}

@article{Hevner2004,
  title = {Design {{Science}} in {{Information Systems Research}}},
  author = {Hevner, Alan R. and March, Salvatore T. and Park, Jinsoo and Ram, Sudha},
  year = {2004},
  journal = {MIS Quarterly},
  volume = {28},
  number = {1},
  pages = {75},
  publisher = {{JSTOR}},
  doi = {10.2307/25148625},
}

@article{Peffers2007,
  title = {A {{Design Science Research Methodology}} for {{Information Systems Research}}},
  author = {Peffers, Ken and Tuunanen, Tuure and Rothenberger, Marcus A. and Chatterjee, Samir},
  year = {2007},
  month = dec,
  journal = {Journal of Management Information Systems},
  volume = {24},
  number = {3},
  pages = {45--77},
  publisher = {{Informa UK Limited}},
  doi = {10.2753/mis0742-1222240302},
}

@article{Simon1988,
  title = {The {{Science}} of {{Design}}: {{Creating}} the {{Artificial}}},
  author = {Simon, Herbert A.},
  year = {1988},
  journal = {Design Issues},
  volume = {4},
  number = {1/2},
  pages = {67},
  publisher = {{JSTOR}},
  doi = {10.2307/1511391},
}

@online{NumPyDevelopers2022,
  title = {Numpy {{Polynomial}}.Fit},
  author = {{NumPy Developers}},
  year = {2022},
  url = {https://numpy.org/doc/stable/reference/generated/numpy.polynomial.polynomial.Polynomial.fit.html},
  urldate = {2022-05-18},
}


@online{GenomeResearchLimited2022,
  title = {Samtools-Flagstat Manual Page},
  author = {{Genome Research Limited}},
  year = {2022},
  month = aug,
  url = {http://www.htslib.org/doc/samtools-flagstat.html},
  urldate = {2022-10-06},
}

@book{Palladino2002,
  title = {Understanding the {{Human Genome Project}}},
  author = {Palladino, Michael Angelo},
  year = {2002},
  publisher = {{Benjamin Cummings}},
  abstract = {A brief booklet that explains in accessible language what readers need to understand about The Human Genome Project (HGP). This reference tool presents the background, findings, scientific and medical applications, social and ethical implications, and helps readers understand timely issues concerning The Human Genome Project. This brief 32 page booklet is a useful supplement to core books in Intro Biology (non-majors/majors), General Biology (majors), Genetics, Human Genetics (non-majors), Human Biology, Intro Biochemistry, and Intro Cell and Molecular Biology. It also includes relevant web resources and exercises for readers. For college instructors and students.},
  isbn = {978-0-8053-6774-4},
}

@online{IlluminaInc.2022a,
  title = {{{NovaSeq}} 6000 {{System}}},
  author = {{Illumina, Inc.}},
  year = {2022},
  url = {https://www.illumina.com/systems/sequencing-platforms/novaseq.html},
  urldate = {2022-10-11},
  langid = {english},
}


@article{Schloss2008,
  title = {How to Get Genomes at One Ten-Thousandth the Cost},
  author = {Schloss, Jeffery A.},
  year = {2008},
  month = oct,
  journal = {Nature Biotechnology},
  volume = {26},
  number = {10},
  pages = {1113--1115},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt1008-1113},
  abstract = {The NHGRI's Advanced DNA Sequencing Technology program is spearheading the development of platforms that will bring routine whole-genome sequencing closer to reality.},
}


@article{Davey2011,
  title = {Genome-Wide Genetic Marker Discovery and Genotyping Using next-Generation Sequencing},
  author = {Davey, John W. and Hohenlohe, Paul A. and Etter, Paul D. and Boone, Jason Q. and Catchen, Julian M. and Blaxter, Mark L.},
  year = {2011},
  month = jul,
  journal = {Nature Reviews Genetics},
  volume = {12},
  number = {7},
  pages = {499--510},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg3012},
  abstract = {New methods that make use of high-throughput sequencing are enabling the simultaneous discovery and sequencing of thousands of genetic markers across whole genomes.These methods can be used to study wild populations of tens or hundreds of individuals for which genomic resources were not previously available.They also enable the rapid genotyping of hundreds of individuals in a mapping cross, for quantitative trait locus (QTL) mapping and marker-assisted selection.We describe best practices and make recommendations for a group of methods involving the use of restriction enzymes, namely reduced-representation libraries, complexity reduction of polymorphic sequences, restriction-site-associated DNA sequencing, multiplexed shotgun genotyping and genotyping by sequencing.We discuss the impact of several factors \textemdash{} such as the availability of genomic resources, the levels of polymorphism, the pooling of samples and the choice of restriction enzyme \textemdash{} on the design and implementation of high-throughput marker discovery and genotyping experiments.The analysis of data from these methods can be challenging and new methods for processing high-throughput marker data are described.At present these methods are far more economical than whole-genome sequencing. We discuss how this situation is likely to change over the next few years, as sequencing costs continue to fall rapidly.},
}

@article{Fuller2009,
  title = {The Challenges of Sequencing by Synthesis},
  author = {Fuller, Carl W. and Middendorf, Lyle R. and Benner, Steven A. and Church, George M. and Harris, Timothy and Huang, Xiaohua and Jovanovich, Stevan B. and Nelson, John R. and Schloss, Jeffery A. and Schwartz, David C. and Vezenov, Dmitri V.},
  year = {2009},
  month = nov,
  journal = {Nature Biotechnology},
  volume = {27},
  number = {11},
  pages = {1013--1023},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt.1585},
  abstract = {DNA sequencing-by-synthesis (SBS) technology, using a polymerase or ligase enzyme as its core biochemistry, has already been incorporated in several second-generation DNA sequencing systems with significant performance. Notwithstanding the substantial success of these SBS platforms, challenges continue to limit the ability to reduce the cost of sequencing a human genome to \$100,000 or less. Achieving dramatically reduced cost with enhanced throughput and quality will require the seamless integration of scientific and technological effort across disciplines within biochemistry, chemistry, physics and engineering. The challenges include sample preparation, surface chemistry, fluorescent labels, optimizing the enzyme-substrate system, optics, instrumentation, understanding tradeoffs of throughput versus accuracy, and read-length/phasing limitations. By framing these challenges in a manner accessible to a broad community of scientists and engineers, we hope to solicit input from the broader research community on means of accelerating the advancement of genome sequencing technology.},
}

@article{Holt2008,
  title = {The New Paradigm of Flow Cell Sequencing},
  author = {Holt, Robert A. and Jones, Steven J. M.},
  year = {2008},
  month = jun,
  journal = {Genome Research},
  volume = {18},
  number = {6},
  pages = {839--846},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.073262.107},
  abstract = {DNA sequencing is in a period of rapid change, in which capillary sequencing is no longer the technology of choice for most ultra-high-throughput applications. A new generation of instruments that utilize primed synthesis in flow cells to obtain, simultaneously, the sequence of millions of different DNA templates has changed the field. We compare and contrast these new sequencing platforms in terms of stage of development, instrument configuration, template format, sequencing chemistry, throughput capability, operating cost, data handling issues, and error models. While these platforms outperform capillary instruments in terms of bases per day and cost per base, the short length of sequence reads obtained from most instruments and the limited number of samples that can be run simultaneously imposes some practical constraints on sequencing applications. However, recently developed methods for paired-end sequencing and for array-based direct selection of desired templates from complex mixtures extend the utility of these platforms for genome analysis. Given the ever increasing demand for DNA sequence information, we can expect continuous improvement of this new generation of instruments and their eventual replacement by even more powerful technology.},
  pmid = {18519653},
}

@article{Li2008,
  title = {Mapping Short {{DNA}} Sequencing Reads and Calling Variants Using Mapping Quality Scores},
  author = {Li, Heng and Ruan, Jue and Durbin, Richard},
  year = {2008},
  month = nov,
  journal = {Genome Research},
  volume = {18},
  number = {11},
  pages = {1851--1858},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.078212.108},
  abstract = {New sequencing technologies promise a new era in the use of DNA sequence. However, some of these technologies produce very short reads, typically of a few tens of base pairs, and to use these reads effectively requires new algorithms and software. In particular, there is a major issue in efficiently aligning short reads to a reference genome and handling ambiguity or lack of accuracy in this alignment. Here we introduce the concept of mapping quality, a measure of the confidence that a read actually comes from the position it is aligned to by the mapping algorithm. We describe the software MAQ that can build assemblies by mapping shotgun short reads to a reference genome, using quality scores to derive genotype calls of the consensus sequence of a diploid genome, e.g., from a human sample. MAQ makes full use of mate-pair information and estimates the error probability of each read alignment. Error probabilities are also derived for the final genotype calls, using a Bayesian statistical model that incorporates the mapping qualities, error probabilities from the raw sequence quality scores, sampling of the two haplotypes, and an empirical model for correlated errors at a site. Both read mapping and genotype calling are evaluated on simulated data and real data. MAQ is accurate, efficient, versatile, and user-friendly. It is freely available at http://maq.sourceforge.net.},
  pmid = {18714091},
}

@online{Caetano-Anolles2022,
  title = {Reference Genome},
  author = {{Caetano-Anolles}, Derek},
  year = {2022},
  month = sep,
  url = {https://gatk.broadinstitute.org/hc/en-us/articles/360035891071-Reference-genome},
  urldate = {2022-10-12},
  abstract = {This document covers the general motivation behind the use of genome references, as well as some terminology and related considerations. For more specific information about human genome reference a...},
}


@online{AmazonWebServices2022b,
  title = {{{AWS Snowball Edge Device Specifications}}},
  author = {{Amazon Web Services}},
  year = {2022},
  url = {https://docs.aws.amazon.com/snowball/latest/developer-guide/sbe-specifications.html},
  urldate = {2022-10-25},
}

@article{Schneider2017,
  title = {Evaluation of {{GRCh38}} and de Novo Haploid Genome Assemblies Demonstrates the Enduring Quality of the Reference Assembly},
  author = {Schneider, Valerie A. and {Graves-Lindsay}, Tina and Howe, Kerstin and Bouk, Nathan and Chen, Hsiu-Chuan and Kitts, Paul A. and Murphy, Terence D. and Pruitt, Kim D. and {Thibaud-Nissen}, Fran{\c c}oise and Albracht, Derek and Fulton, Robert S. and Kremitzki, Milinn and Magrini, Vincent and Markovic, Chris and McGrath, Sean and Steinberg, Karyn Meltz and Auger, Kate and Chow, William and Collins, Joanna and Harden, Glenn and Hubbard, Timothy and Pelan, Sarah and Simpson, Jared T. and Threadgold, Glen and Torrance, James and Wood, Jonathan M. and Clarke, Laura and Koren, Sergey and Boitano, Matthew and Peluso, Paul and Li, Heng and Chin, Chen-Shan and Phillippy, Adam M. and Durbin, Richard and Wilson, Richard K. and Flicek, Paul and Eichler, Evan E. and Church, Deanna M.},
  year = {2017},
  month = may,
  journal = {Genome Research},
  volume = {27},
  number = {5},
  pages = {849--864},
  publisher = {{Cold Spring Harbor Lab}},
  issn = {1088-9051, 1549-5469},
  doi = {10.1101/gr.213611.116},
  abstract = {The human reference genome assembly plays a central role in nearly all aspects of today's basic and clinical research. GRCh38 is the first coordinate-changing assembly update since 2009; it reflects the resolution of roughly 1000 issues and encompasses modifications ranging from thousands of single base changes to megabase-scale path reorganizations, gap closures, and localization of previously orphaned sequences. We developed a new approach to sequence generation for targeted base updates and used data from new genome mapping technologies and single haplotype resources to identify and resolve larger assembly issues. For the first time, the reference assembly contains sequence-based representations for the centromeres. We also expanded the number of alternate loci to create a reference that provides a more robust representation of human population variation. We demonstrate that the updates render the reference an improved annotation substrate, alter read alignments in unchanged regions, and impact variant interpretation at clinically relevant loci. We additionally evaluated a collection of new de novo long-read haploid assemblies and conclude that although the new assemblies compare favorably to the reference with respect to continuity, error rate, and gene completeness, the reference still provides the best representation for complex genomic regions and coding sequences. We assert that the collected updates in GRCh38 make the newer assembly a more robust substrate for comprehensive analyses that will promote our understanding of human biology and advance our efforts to improve health.},
  langid = {english},
  pmid = {28396521}
}

@article{Pan2019,
  title = {Similarities and Differences between Variants Called with Human Reference Genome {{HG19}} or {{HG38}}},
  author = {Pan, Bohu and Kusko, Rebecca and Xiao, Wenming and Zheng, Yuanting and Liu, Zhichao and Xiao, Chunlin and Sakkiah, Sugunadevi and Guo, Wenjing and Gong, Ping and Zhang, Chaoyang and Ge, Weigong and Shi, Leming and Tong, Weida and Hong, Huixiao},
  year = {2019},
  month = mar,
  journal = {BMC Bioinformatics},
  volume = {20},
  number = {2},
  pages = {101},
  issn = {1471-2105},
  doi = {10.1186/s12859-019-2620-0},
  abstract = {Reference genome selection is a prerequisite for successful analysis of next generation sequencing (NGS) data. Current practice employs one of the two most recent human reference genome versions: HG19 or HG38. To date, the impact of genome version on SNV identification has not been rigorously assessed.},
  keywords = {Calling pipeline comparison,Human reference genomes,Next generation sequencing,SNV}
}

@article{Guo2017,
  title = {Improvements and Impacts of {{GRCh38}} Human Reference on High Throughput Sequencing Data Analysis},
  author = {Guo, Yan and Dai, Yulin and Yu, Hui and Zhao, Shilin and Samuels, David C. and Shyr, Yu},
  year = {2017},
  month = mar,
  journal = {Genomics},
  volume = {109},
  number = {2},
  pages = {83--90},
  issn = {0888-7543},
  doi = {10.1016/j.ygeno.2017.01.005},
  abstract = {Analyses of high throughput sequencing data starts with alignment against a reference genome, which is the foundation for all re-sequencing data analyses. Each new release of the human reference genome has been augmented with improved accuracy and completeness. It is presumed that the latest release of human reference genome, GRCh38 will contribute more to high throughput sequencing data analysis by providing more accuracy. But the amount of improvement has not yet been quantified. We conducted a study to compare the genomic analysis results between the GRCh38 reference and its predecessor GRCh37. Through analyses of alignment, single nucleotide polymorphisms, small insertion/deletions, copy number and structural variants, we show that GRCh38 offers overall more accurate analysis of human sequencing data. More importantly, GRCh38 produced fewer false positive structural variants. In conclusion, GRCh38 is an improvement over GRCh37 not only from the genome assembly aspect, but also yields more reliable genomic analysis results.},
  langid = {english},
  keywords = {Copy number variation,GRCh37,GRCh38,High throughput sequencing,Human reference genome,SNP,Structural variant}
}

@article{Church2015,
  title = {Extending Reference Assembly Models},
  author = {Church, Deanna M. and Schneider, Valerie A. and Steinberg, Karyn Meltz and Schatz, Michael C. and Quinlan, Aaron R. and Chin, Chen-Shan and Kitts, Paul A. and Aken, Bronwen and Marth, Gabor T. and Hoffman, Michael M. and Herrero, Javier and Mendoza, M Lisandra Zepeda and Durbin, Richard and Flicek, Paul},
  year = {2015},
  month = jan,
  journal = {Genome Biology},
  volume = {16},
  number = {1},
  pages = {13},
  issn = {1465-6906},
  doi = {10.1186/s13059-015-0587-3},
  abstract = {The human genome reference assembly is crucial for aligning and analyzing sequence data, and for genome annotation, among other roles. However, the models and analysis assumptions that underlie the current assembly need revising to fully represent human sequence diversity. Improved analysis tools and updated data reporting formats are also required.},
  keywords = {Alternative Locus,Assembly Model,Human Genome Project,Reference Assembly,Sequence Identifier}
}

@article{Lander2001,
  title = {Initial Sequencing and Analysis of the Human Genome},
  author = {Lander, Eric S. and Linton, Lauren M. and Birren, Bruce and Nusbaum, Chad and Zody, Michael C. and Baldwin, Jennifer and Devon, Keri and Dewar, Ken and Doyle, Michael and FitzHugh, William and Funke, Roel and Gage, Diane and Harris, Katrina and Heaford, Andrew and Howland, John and Kann, Lisa and Lehoczky, Jessica and LeVine, Rosie and McEwan, Paul and McKernan, Kevin and Meldrim, James and Mesirov, Jill P. and Miranda, Cher and Morris, William and Naylor, Jerome and Raymond, Christina and Rosetti, Mark and Santos, Ralph and Sheridan, Andrew and Sougnez, Carrie and {Stange-Thomann}, Nicole and Stojanovic, Nikola and Subramanian, Aravind and Wyman, Dudley and Rogers, Jane and Sulston, John and Ainscough, Rachael and Beck, Stephan and Bentley, David and Burton, John and Clee, Christopher and Carter, Nigel and Coulson, Alan and Deadman, Rebecca and Deloukas, Panos and Dunham, Andrew and Dunham, Ian and Durbin, Richard and French, Lisa and Grafham, Darren and Gregory, Simon and Hubbard, Tim and Humphray, Sean and Hunt, Adrienne and Jones, Matthew and Lloyd, Christine and McMurray, Amanda and Matthews, Lucy and Mercer, Simon and Milne, Sarah and Mullikin, James C. and Mungall, Andrew and Plumb, Robert and Ross, Mark and Shownkeen, Ratna and Sims, Sarah and Waterston, Robert H. and Wilson, Richard K. and Hillier, LaDeana W. and McPherson, John D. and Marra, Marco A. and Mardis, Elaine R. and Fulton, Lucinda A. and Chinwalla, Asif T. and Pepin, Kymberlie H. and Gish, Warren R. and Chissoe, Stephanie L. and Wendl, Michael C. and Delehaunty, Kim D. and Miner, Tracie L. and Delehaunty, Andrew and Kramer, Jason B. and Cook, Lisa L. and Fulton, Robert S. and Johnson, Douglas L. and Minx, Patrick J. and Clifton, Sandra W. and Hawkins, Trevor and Branscomb, Elbert and Predki, Paul and Richardson, Paul and Wenning, Sarah and Slezak, Tom and Doggett, Norman and Cheng, Jan-Fang and Olsen, Anne and Lucas, Susan and Elkin, Christopher and Uberbacher, Edward and Frazier, Marvin and Gibbs, Richard A. and Muzny, Donna M. and Scherer, Steven E. and Bouck, John B. and Sodergren, Erica J. and Worley, Kim C. and Rives, Catherine M. and Gorrell, James H. and Metzker, Michael L. and Naylor, Susan L. and Kucherlapati, Raju S. and Nelson, David L. and Weinstock, George M. and Sakaki, Yoshiyuki and Fujiyama, Asao and Hattori, Masahira and Yada, Tetsushi and Toyoda, Atsushi and Itoh, Takehiko and Kawagoe, Chiharu and Watanabe, Hidemi and Totoki, Yasushi and Taylor, Todd and Weissenbach, Jean and Heilig, Roland and Saurin, William and Artiguenave, Francois and Brottier, Philippe and Bruls, Thomas and Pelletier, Eric and Robert, Catherine and Wincker, Patrick and Rosenthal, Andr{\'e} and Platzer, Matthias and Nyakatura, Gerald and Taudien, Stefan and Rump, Andreas and Smith, Douglas R. and {Doucette-Stamm}, Lynn and Rubenfield, Marc and Weinstock, Keith and Lee, Hong Mei and Dubois, JoAnn and Yang, Huanming and Yu, Jun and Wang, Jian and Huang, Guyang and Gu, Jun and Hood, Leroy and Rowen, Lee and Madan, Anup and Qin, Shizen and Davis, Ronald W. and Federspiel, Nancy A. and Abola, A. Pia and Proctor, Michael J. and Roe, Bruce A. and Chen, Feng and Pan, Huaqin and Ramser, Juliane and Lehrach, Hans and Reinhardt, Richard and McCombie, W. Richard and {de la Bastide}, Melissa and Dedhia, Neilay and Bl{\"o}cker, Helmut and Hornischer, Klaus and Nordsiek, Gabriele and Agarwala, Richa and Aravind, L. and Bailey, Jeffrey A. and Bateman, Alex and Batzoglou, Serafim and Birney, Ewan and Bork, Peer and Brown, Daniel G. and Burge, Christopher B. and Cerutti, Lorenzo and Chen, Hsiu-Chuan and Church, Deanna and Clamp, Michele and Copley, Richard R. and Doerks, Tobias and Eddy, Sean R. and Eichler, Evan E. and Furey, Terrence S. and Galagan, James and Gilbert, James G. R. and Harmon, Cyrus and Hayashizaki, Yoshihide and Haussler, David and Hermjakob, Henning and Hokamp, Karsten and Jang, Wonhee and Johnson, L. Steven and Jones, Thomas A. and Kasif, Simon and Kaspryzk, Arek and Kennedy, Scot and Kent, W. James and Kitts, Paul and Koonin, Eugene V. and Korf, Ian and Kulp, David and Lancet, Doron and Lowe, Todd M. and McLysaght, Aoife and Mikkelsen, Tarjei and Moran, John V. and Mulder, Nicola and Pollara, Victor J. and Ponting, Chris P. and Schuler, Greg and Schultz, J{\"o}rg and Slater, Guy and Smit, Arian F. A. and Stupka, Elia and Szustakowki, Joseph and {Thierry-Mieg}, Danielle and {Thierry-Mieg}, Jean and Wagner, Lukas and Wallis, John and Wheeler, Raymond and Williams, Alan and Wolf, Yuri I. and Wolfe, Kenneth H. and Yang, Shiaw-Pyng and Yeh, Ru-Fang and Collins, Francis and Guyer, Mark S. and Peterson, Jane and Felsenfeld, Adam and Wetterstrand, Kris A. and Myers, Richard M. and Schmutz, Jeremy and Dickson, Mark and Grimwood, Jane and Cox, David R. and Olson, Maynard V. and Kaul, Rajinder and Raymond, Christopher and Shimizu, Nobuyoshi and Kawasaki, Kazuhiko and Minoshima, Shinsei and Evans, Glen A. and Athanasiou, Maria and Schultz, Roger and Patrinos, Aristides and Morgan, Michael J. and {International Human Genome Sequencing Consortium} and {Whitehead Institute for Biomedical Research}, Center for Genome Research: and {The Sanger Centre:} and {Washington University Genome Sequencing Center} and {US DOE Joint Genome Institute:} and {Baylor College of Medicine Human Genome Sequencing Center:} and {RIKEN Genomic Sciences Center:} and {Genoscope and CNRS UMR-8030:} and {Department of Genome Analysis}, Institute of Molecular Biotechnology: and {GTC Sequencing Center:} and {Beijing Genomics Institute/Human Genome Center:} and Multimegabase Sequencing Center, The Institute for Systems Biology: and {Stanford Genome Technology Center:} and {University of Oklahoma's Advanced Center for Genome Technology:} and {Max Planck Institute for Molecular Genetics:} and Cold Spring Harbor Laboratory, Lita Annenberg Hazen Genome Center: and {GBF\textemdash German Research Centre for Biotechnology:} and includes individuals listed under other headings):{\aftergroup\ignorespaces} {*Genome Analysis Group (listed in alphabetical order}, also and {Scientific management: National Human Genome Research Institute}, US National Institutes of Health: and {Stanford Human Genome Center:} and {University of Washington Genome Center:} and {Department of Molecular Biology}, Keio University School of Medicine: and {University of Texas Southwestern Medical Center at Dallas:} and {Office of Science}, US Department of Energy: and {The Wellcome Trust:}},
  year = {2001},
  month = feb,
  journal = {Nature},
  volume = {409},
  number = {6822},
  pages = {860--921},
  publisher = {{Nature Publishing Group}},
  issn = {1476-4687},
  doi = {10.1038/35057062},
  abstract = {The human genome holds an extraordinary trove of information about human development, physiology, medicine and evolution. Here we report the results of an international collaboration to produce and make freely available a draft sequence of the human genome. We also present an initial analysis of the data, describing some of the insights that can be gleaned from the sequence.},
}

@article{Venter2001,
  title = {The {{Sequence}} of the {{Human Genome}}},
  author = {Venter, J. Craig and Adams, Mark D. and Myers, Eugene W. and Li, Peter W. and Mural, Richard J. and Sutton, Granger G. and Smith, Hamilton O. and Yandell, Mark and Evans, Cheryl A. and Holt, Robert A. and Gocayne, Jeannine D. and Amanatides, Peter and Ballew, Richard M. and Huson, Daniel H. and Wortman, Jennifer Russo and Zhang, Qing and Kodira, Chinnappa D. and Zheng, Xiangqun H. and Chen, Lin and Skupski, Marian and Subramanian, Gangadharan and Thomas, Paul D. and Zhang, Jinghui and Gabor Miklos, George L. and Nelson, Catherine and Broder, Samuel and Clark, Andrew G. and Nadeau, Joe and McKusick, Victor A. and Zinder, Norton and Levine, Arnold J. and Roberts, Richard J. and Simon, Mel and Slayman, Carolyn and Hunkapiller, Michael and Bolanos, Randall and Delcher, Arthur and Dew, Ian and Fasulo, Daniel and Flanigan, Michael and Florea, Liliana and Halpern, Aaron and Hannenhalli, Sridhar and Kravitz, Saul and Levy, Samuel and Mobarry, Clark and Reinert, Knut and Remington, Karin and {Abu-Threideh}, Jane and Beasley, Ellen and Biddick, Kendra and Bonazzi, Vivien and Brandon, Rhonda and Cargill, Michele and Chandramouliswaran, Ishwar and Charlab, Rosane and Chaturvedi, Kabir and Deng, Zuoming and Francesco, Valentina Di and Dunn, Patrick and Eilbeck, Karen and Evangelista, Carlos and Gabrielian, Andrei E. and Gan, Weiniu and Ge, Wangmao and Gong, Fangcheng and Gu, Zhiping and Guan, Ping and Heiman, Thomas J. and Higgins, Maureen E. and Ji, Rui-Ru and Ke, Zhaoxi and Ketchum, Karen A. and Lai, Zhongwu and Lei, Yiding and Li, Zhenya and Li, Jiayin and Liang, Yong and Lin, Xiaoying and Lu, Fu and Merkulov, Gennady V. and Milshina, Natalia and Moore, Helen M. and Naik, Ashwinikumar K and Narayan, Vaibhav A. and Neelam, Beena and Nusskern, Deborah and Rusch, Douglas B. and Salzberg, Steven and Shao, Wei and Shue, Bixiong and Sun, Jingtao and Wang, Zhen Yuan and Wang, Aihui and Wang, Xin and Wang, Jian and Wei, Ming-Hui and Wides, Ron and Xiao, Chunlin and Yan, Chunhua and Yao, Alison and Ye, Jane and Zhan, Ming and Zhang, Weiqing and Zhang, Hongyu and Zhao, Qi and Zheng, Liansheng and Zhong, Fei and Zhong, Wenyan and Zhu, Shiaoping C. and Zhao, Shaying and Gilbert, Dennis and Baumhueter, Suzanna and Spier, Gene and Carter, Christine and Cravchik, Anibal and Woodage, Trevor and Ali, Feroze and An, Huijin and Awe, Aderonke and Baldwin, Danita and Baden, Holly and Barnstead, Mary and Barrow, Ian and Beeson, Karen and Busam, Dana and Carver, Amy and Center, Angela and Cheng, Ming Lai and Curry, Liz and Danaher, Steve and Davenport, Lionel and Desilets, Raymond and Dietz, Susanne and Dodson, Kristina and Doup, Lisa and Ferriera, Steven and Garg, Neha and Gluecksmann, Andres and Hart, Brit and Haynes, Jason and Haynes, Charles and Heiner, Cheryl and Hladun, Suzanne and Hostin, Damon and Houck, Jarrett and Howland, Timothy and Ibegwam, Chinyere and Johnson, Jeffery and Kalush, Francis and Kline, Lesley and Koduru, Shashi and Love, Amy and Mann, Felecia and May, David and McCawley, Steven and McIntosh, Tina and McMullen, Ivy and Moy, Mee and Moy, Linda and Murphy, Brian and Nelson, Keith and Pfannkoch, Cynthia and Pratts, Eric and Puri, Vinita and Qureshi, Hina and Reardon, Matthew and Rodriguez, Robert and Rogers, Yu-Hui and Romblad, Deanna and Ruhfel, Bob and Scott, Richard and Sitter, Cynthia and Smallwood, Michelle and Stewart, Erin and Strong, Renee and Suh, Ellen and Thomas, Reginald and Tint, Ni Ni and Tse, Sukyee and Vech, Claire and Wang, Gary and Wetter, Jeremy and Williams, Sherita and Williams, Monica and Windsor, Sandra and {Winn-Deen}, Emily and Wolfe, Keriellen and Zaveri, Jayshree and Zaveri, Karena and Abril, Josep F. and Guig{\'o}, Roderic and Campbell, Michael J. and Sjolander, Kimmen V. and Karlak, Brian and Kejariwal, Anish and Mi, Huaiyu and Lazareva, Betty and Hatton, Thomas and Narechania, Apurva and Diemer, Karen and Muruganujan, Anushya and Guo, Nan and Sato, Shinji and Bafna, Vineet and Istrail, Sorin and Lippert, Ross and Schwartz, Russell and Walenz, Brian and Yooseph, Shibu and Allen, David and Basu, Anand and Baxendale, James and Blick, Louis and Caminha, Marcelo and {Carnes-Stine}, John and Caulk, Parris and Chiang, Yen-Hui and Coyne, My and Dahlke, Carl and Mays, Anne Deslattes and Dombroski, Maria and Donnelly, Michael and Ely, Dale and Esparham, Shiva and Fosler, Carl and Gire, Harold and Glanowski, Stephen and Glasser, Kenneth and Glodek, Anna and Gorokhov, Mark and Graham, Ken and Gropman, Barry and Harris, Michael and Heil, Jeremy and Henderson, Scott and Hoover, Jeffrey and Jennings, Donald and Jordan, Catherine and Jordan, James and Kasha, John and Kagan, Leonid and Kraft, Cheryl and Levitsky, Alexander and Lewis, Mark and Liu, Xiangjun and Lopez, John and Ma, Daniel and Majoros, William and McDaniel, Joe and Murphy, Sean and Newman, Matthew and Nguyen, Trung and Nguyen, Ngoc and Nodell, Marc and Pan, Sue and Peck, Jim and Peterson, Marshall and Rowe, William and Sanders, Robert and Scott, John and Simpson, Michael and Smith, Thomas and Sprague, Arlan and Stockwell, Timothy and Turner, Russell and Venter, Eli and Wang, Mei and Wen, Meiyuan and Wu, David and Wu, Mitchell and Xia, Ashley and Zandieh, Ali and Zhu, Xiaohong},
  year = {2001},
  month = feb,
  journal = {Science},
  volume = {291},
  number = {5507},
  pages = {1304--1351},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.1058040}
}

@article{Mardis2008a,
  title = {Next-Generation {{DNA}} Sequencing Methods},
  author = {Mardis, Elaine R.},
  year = {2008},
  journal = {Annual Review of Genomics and Human Genetics},
  volume = {9},
  pages = {387--402},
  issn = {1527-8204},
  doi = {10.1146/annurev.genom.9.081307.164359},
  abstract = {Recent scientific discoveries that resulted from the application of next-generation DNA sequencing technologies highlight the striking impact of these massively parallel platforms on genetics. These new methods have expanded previously focused readouts from a variety of DNA preparation protocols to a genome-wide scale and have fine-tuned their resolution to single base precision. The sequencing of RNA also has transitioned and now includes full-length cDNA analyses, serial analysis of gene expression (SAGE)-based methods, and noncoding RNA discovery. Next-generation sequencing has also enabled novel applications such as the sequencing of ancient DNA samples, and has substantially widened the scope of metagenomic analysis of environmentally derived samples. Taken together, an astounding potential exists for these technologies to bring enormous change in genetic and biological research and to enhance our fundamental biological knowledge.},
  pmid = {18576944}
}

@article{Mardis2008b,
  title = {The Impact of Next-Generation Sequencing Technology on Genetics},
  author = {Mardis, Elaine R.},
  year = {2008},
  month = mar,
  journal = {Trends in genetics: TIG},
  volume = {24},
  number = {3},
  pages = {133--141},
  issn = {0168-9525},
  doi = {10.1016/j.tig.2007.12.007},
  abstract = {If one accepts that the fundamental pursuit of genetics is to determine the genotypes that explain phenotypes, the meteoric increase of DNA sequence information applied toward that pursuit has nowhere to go but up. The recent introduction of instruments capable of producing millions of DNA sequence reads in a single run is rapidly changing the landscape of genetics, providing the ability to answer questions with heretofore unimaginable speed. These technologies will provide an inexpensive, genome-wide sequence readout as an endpoint to applications ranging from chromatin immunoprecipitation, mutation mapping and polymorphism discovery to noncoding RNA discovery. Here I survey next-generation sequencing technologies and consider how they can provide a more complete picture of how the genome shapes the organism.},
  pmid = {18262675}
}

@article{Shendure2008,
  title = {Next-Generation {{DNA}} Sequencing},
  author = {Shendure, Jay and Ji, Hanlee},
  year = {2008},
  month = oct,
  journal = {Nature Biotechnology},
  volume = {26},
  number = {10},
  pages = {1135--1145},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/nbt1486},
  abstract = {DNA sequence represents a single format onto which a broad range of biological phenomena can be projected for high-throughput data collection. Over the past three years, massively parallel DNA sequencing platforms have become widely available, reducing the cost of DNA sequencing by over two orders of magnitude, and democratizing the field by putting the sequencing capacity of a major genome center in the hands of individual investigators. These new technologies are rapidly evolving, and near-term challenges include the development of robust protocols for generating sequencing libraries, building effective new approaches to data-analysis, and often a rethinking of experimental design. Next-generation DNA sequencing has the potential to dramatically accelerate biological and biomedical research, by enabling the comprehensive analysis of genomes, transcriptomes and interactomes to become inexpensive, routine and widespread, rather than requiring significant production-scale efforts.}
}

@article{voelkerding2009,
  title = {Next-{{Generation Sequencing}}: {{From Basic Research}} to {{Diagnostics}}},
  author = {Voelkerding, Karl V. and Dames, Shale A. and Durtschi, Jacob D.},
  year = {2009},
  month = apr,
  journal = {Clinical Chemistry},
  volume = {55},
  number = {4},
  pages = {641--658},
  publisher = {{Oxford University Press (OUP)}},
  doi = {10.1373/clinchem.2008.112789},
}

@article{metzker2010,
  title = {Sequencing Technologies \textemdash{} the next Generation},
  author = {Metzker, Michael L.},
  year = {2010},
  month = jan,
  journal = {Nature Reviews Genetics},
  volume = {11},
  number = {1},
  pages = {31--46},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0064},
  doi = {10.1038/nrg2626},
  abstract = {The major advance offered by next-generation sequencing (NGS) technologies is the ability to produce, in some cases, in excess of one billion short reads per instrument run, which makes them useful for many biological applications.The variety of NGS features makes it likely that multiple platforms will coexist in the marketplace, with some having clear advantages for particular applications over others.The leading NGS platforms use clonally amplified templates, which are not affected by the arbitrary losses of genomic sequences that are inherent in bacterial cloning methods.An important advantage of single-molecule template platforms is that PCR is not required. PCR can create mutations that masquerade as sequence variants and amplification bias that underrepresents AT-rich and GC-rich regions in target sequences.There are four primary NGS chemistry methods: cyclic reversible termination, sequencing by ligation, pyrosequencing and real-time sequencing, which are described in this Review.To call sequence variants in genomes, NGS reads are aligned to a reference sequence using various bioinformatics mapping tools.Whole-genome sequencing using current NGS platforms is still expensive, but targeting regions of interest may provide an interim solution to analysing hundreds, if not thousands, of samples.To date, the sequences of twelve human genomes have been published using a number of NGS platforms, marking the beginning of personalized genomics.NGS costs will continue to drop in the foreseeable future, although the cost reduction should be weighed against the quality of the produced genome sequence.},
  copyright = {2010 Nature Publishing Group},
  langid = {english}
}

@article{bentley2008,
  title = {Accurate Whole Human Genome Sequencing Using Reversible Terminator Chemistry},
  author = {Bentley, David R. and Balasubramanian, Shankar and Swerdlow, Harold P. and Smith, Geoffrey P. and Milton, John and Brown, Clive G. and Hall, Kevin P. and Evers, Dirk J. and Barnes, Colin L. and Bignell, Helen R. and Boutell, Jonathan M. and Bryant, Jason and Carter, Richard J. and Keira Cheetham, R. and Cox, Anthony J. and Ellis, Darren J. and Flatbush, Michael R. and Gormley, Niall A. and Humphray, Sean J. and Irving, Leslie J. and Karbelashvili, Mirian S. and Kirk, Scott M. and Li, Heng and Liu, Xiaohai and Maisinger, Klaus S. and Murray, Lisa J. and Obradovic, Bojan and Ost, Tobias and Parkinson, Michael L. and Pratt, Mark R. and Rasolonjatovo, Isabelle M. J. and Reed, Mark T. and Rigatti, Roberto and Rodighiero, Chiara and Ross, Mark T. and Sabot, Andrea and Sankar, Subramanian V. and Scally, Aylwyn and Schroth, Gary P. and Smith, Mark E. and Smith, Vincent P. and Spiridou, Anastassia and Torrance, Peta E. and Tzonev, Svilen S. and Vermaas, Eric H. and Walter, Klaudia and Wu, Xiaolin and Zhang, Lu and Alam, Mohammed D. and Anastasi, Carole and Aniebo, Ify C. and Bailey, David M. D. and Bancarz, Iain R. and Banerjee, Saibal and Barbour, Selena G. and Baybayan, Primo A. and Benoit, Vincent A. and Benson, Kevin F. and Bevis, Claire and Black, Phillip J. and Boodhun, Asha and Brennan, Joe S. and Bridgham, John A. and Brown, Rob C. and Brown, Andrew A. and Buermann, Dale H. and Bundu, Abass A. and Burrows, James C. and Carter, Nigel P. and Castillo, Nestor and Chiara E Catenazzi, Maria and Chang, Simon and Neil Cooley, R. and Crake, Natasha R. and Dada, Olubunmi O. and Diakoumakos, Konstantinos D. and {Dominguez-Fernandez}, Belen and Earnshaw, David J. and Egbujor, Ugonna C. and Elmore, David W. and Etchin, Sergey S. and Ewan, Mark R. and Fedurco, Milan and Fraser, Louise J. and Fuentes Fajardo, Karin V. and Scott Furey, W. and George, David and Gietzen, Kimberley J. and Goddard, Colin P. and Golda, George S. and Granieri, Philip A. and Green, David E. and Gustafson, David L. and Hansen, Nancy F. and Harnish, Kevin and Haudenschild, Christian D. and Heyer, Narinder I. and Hims, Matthew M. and Ho, Johnny T. and Horgan, Adrian M. and Hoschler, Katya and Hurwitz, Steve and Ivanov, Denis V. and Johnson, Maria Q. and James, Terena and Huw Jones, T. A. and Kang, Gyoung-Dong and Kerelska, Tzvetana H. and Kersey, Alan D. and Khrebtukova, Irina and Kindwall, Alex P. and Kingsbury, Zoya and {Kokko-Gonzales}, Paula I. and Kumar, Anil and Laurent, Marc A. and Lawley, Cynthia T. and Lee, Sarah E. and Lee, Xavier and Liao, Arnold K. and Loch, Jennifer A. and Lok, Mitch and Luo, Shujun and Mammen, Radhika M. and Martin, John W. and McCauley, Patrick G. and McNitt, Paul and Mehta, Parul and Moon, Keith W. and Mullens, Joe W. and Newington, Taksina and Ning, Zemin and Ling Ng, Bee and Novo, Sonia M. and O'Neill, Michael J. and Osborne, Mark A. and Osnowski, Andrew and Ostadan, Omead and Paraschos, Lambros L. and Pickering, Lea and Pike, Andrew C. and Pike, Alger C. and Chris Pinkard, D. and Pliskin, Daniel P. and Podhasky, Joe and Quijano, Victor J. and Raczy, Come and Rae, Vicki H. and Rawlings, Stephen R. and Chiva Rodriguez, Ana and Roe, Phyllida M. and Rogers, John and Rogert Bacigalupo, Maria C. and Romanov, Nikolai and Romieu, Anthony and Roth, Rithy K. and Rourke, Natalie J. and Ruediger, Silke T. and Rusman, Eli and {Sanches-Kuiper}, Raquel M. and Schenker, Martin R. and Seoane, Josefina M. and Shaw, Richard J. and Shiver, Mitch K. and Short, Steven W. and Sizto, Ning L. and Sluis, Johannes P. and Smith, Melanie A. and Ernest Sohna Sohna, Jean and Spence, Eric J. and Stevens, Kim and Sutton, Neil and Szajkowski, Lukasz and Tregidgo, Carolyn L. and Turcatti, Gerardo and Vandevondele, Stephanie and Verhovsky, Yuli and Virk, Selene M. and Wakelin, Suzanne and Walcott, Gregory C. and Wang, Jingwen and Worsley, Graham J. and Yan, Juying and Yau, Ling and Zuerlein, Mike and Rogers, Jane and Mullikin, James C. and Hurles, Matthew E. and McCooke, Nick J. and West, John S. and Oaks, Frank L. and Lundberg, Peter L. and Klenerman, David and Durbin, Richard and Smith, Anthony J.},
  year = {2008},
  month = nov,
  journal = {Nature},
  volume = {456},
  number = {7218},
  pages = {53--59},
  issn = {1476-4687},
  doi = {10.1038/nature07517},
  abstract = {DNA sequence information underpins genetic research, enabling discoveries of important biological or medical benefit. Sequencing projects have traditionally used long (400-800 base pair) reads, but the existence of reference sequences for the human and many other genomes makes it possible to develop new, fast approaches to re-sequencing, whereby shorter reads are compared to a reference to identify intraspecies genetic variation. Here we report an approach that generates several billion bases of accurate nucleotide sequence per experiment at low cost. Single molecules of DNA are attached to a flat surface, amplified in situ and used as templates for synthetic sequencing with fluorescent reversible terminator deoxyribonucleotides. Images of the surface are analysed to generate high-quality sequence. We demonstrate application of this approach to human genome sequencing on flow-sorted X chromosomes and then scale the approach to determine the genome sequence of a male Yoruba from Ibadan, Nigeria. We build an accurate consensus sequence from {$>$}30x average depth of paired 35-base reads. We characterize four million single-nucleotide polymorphisms and four hundred thousand structural variants, many of which were previously unknown. Our approach is effective for accurate, rapid and economical whole-genome re-sequencing and many other biomedical applications.},
  pmcid = {PMC2581791},
  pmid = {18987734}
}

@article{georgakopoulos1995,
  title = {An Overview of Workflow Management: {{From}} Process Modeling to Workflow Automation Infrastructure},
  shorttitle = {An Overview of Workflow Management},
  author = {Georgakopoulos, Diimitrios and Hornick, Mark and Sheth, Amit},
  year = {1995},
  month = apr,
  journal = {Distributed and Parallel Databases},
  volume = {3},
  number = {2},
  pages = {119--153},
  issn = {1573-7578},
  doi = {10.1007/BF01277643},
  abstract = {Today's business enterprises must deal with global competition, reduce the cost of doing business, and rapidly develop new services and products. To address these requirements enterprises must constantly reconsider and optimize the way they do business and change their information systems and applications to support evolving business processes. Workflow technology facilitates these by providing methodologies and software to support (i) business process modeling to capture business processes as workflow specifications, (ii) business process reengineering to optimize specified processes, and (iii) workflow automation to generate workflow implementations from workflow specifications. This paper provides a high-level overview of the current workflow management methodologies and software products. In addition, we discuss the infrastructure technologies that can address the limitations of current commercial workflow technology and extend the scope and mission of workflow management systems to support increased workflow automation in complex real-world environments involving heterogeneous, autonomous, and distributed information systems. In particular, we discuss how distributed object management and customized transaction management can support further advances in the commercial state of the art in this area.}
}

@book{aalst2004,
  title = {Workflow {{Management}}: {{Models}}, {{Methods}}, and {{Systems}}},
  shorttitle = {Workflow {{Management}}},
  author = {van der Aalst, Wil and van Hee, Kees},
  year = {2004},
  publisher = {{MIT Press}},
  abstract = {This book offers a comprehensive introduction to workflow management, the management of business processes with information technology. By defining, analyzing, and redesigning an organization's resources and operations, workflow management systems ensure that the right information reaches the right person or computer application at the right time. The book provides a basic overview of workflow terminology and organization, as well as detailed coverage of workflow modeling with Petri nets. Because Petri nets make definitions easier to understand for nonexperts, they facilitate communication between designers and users. The book includes a chapter of case studies, review exercises, and a glossary. A special Web site developed by the authors, www.workflowcourse.com, features animation, interactive examples, lecture materials, exercises and solutions, relevant links, and other valuable resources for the classroom.},
  isbn = {978-0-262-72046-5}
}

@article{ludascher2006,
  title = {Scientific Workflow Management and the {{Kepler}} System},
  author = {Lud{\"a}scher, Bertram and Altintas, Ilkay and Berkley, Chad and Higgins, Dan and Jaeger, Efrat and Jones, Matthew and Lee, Edward A. and Tao, Jing and Zhao, Yang},
  year = {2006},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {18},
  number = {10},
  pages = {1039--1065},
  issn = {1532-0634},
  doi = {10.1002/cpe.994},
  abstract = {Many scientific disciplines are now data and information driven, and new scientific knowledge is often gained by scientists putting together data analysis and knowledge discovery `pipelines'. A related trend is that more and more scientific communities realize the benefits of sharing their data and computational services, and are thus contributing to a distributed data and computational community infrastructure (a.k.a. `the Grid'). However, this infrastructure is only a means to an end and ideally scientists should not be too concerned with its existence. The goal is for scientists to focus on development and use of what we call scientific workflows. These are networks of analytical steps that may involve, e.g., database access and querying steps, data analysis and mining steps, and many other steps including computationally intensive jobs on high-performance cluster computers. In this paper we describe characteristics of and requirements for scientific workflows as identified in a number of our application projects. We then elaborate on Kepler, a particular scientific workflow system, currently under development across a number of scientific data management projects. We describe some key features of Kepler and its underlying Ptolemy II system, planned extensions, and areas of future research. Kepler is a community-driven, open source project, and we always welcome related projects and new contributors to join. Copyright \textcopyright{} 2005 John Wiley \& Sons, Ltd.}
}

@article{oinn2004,
  title = {Taverna: A Tool for the Composition and Enactment of Bioinformatics Workflows},
  shorttitle = {Taverna},
  author = {Oinn, Tom and Addis, Matthew and Ferris, Justin and Marvin, Darren and Senger, Martin and Greenwood, Mark and Carver, Tim and Glover, Kevin and Pocock, Matthew R. and Wipat, Anil and Li, Peter},
  year = {2004},
  month = nov,
  journal = {Bioinformatics (Oxford, England)},
  volume = {20},
  number = {17},
  pages = {3045--3054},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bth361},
  abstract = {MOTIVATION: In silico experiments in bioinformatics involve the co-ordinated use of computational tools and information repositories. A growing number of these resources are being made available with programmatic access in the form of Web services. Bioinformatics scientists will need to orchestrate these Web services in workflows as part of their analyses. RESULTS: The Taverna project has developed a tool for the composition and enactment of bioinformatics workflows for the life sciences community. The tool includes a workbench application which provides a graphical user interface for the composition of workflows. These workflows are written in a new language called the simple conceptual unified flow language (Scufl), where by each step within a workflow represents one atomic task. Two examples are used to illustrate the ease by which in silico experiments can be represented as Scufl workflows using the workbench application.},
  pmid = {15201187}
}

@article{giardine2005,
  title = {Galaxy: {{A}} Platform for Interactive Large-Scale Genome Analysis},
  shorttitle = {Galaxy},
  author = {Giardine, Belinda and Riemer, Cathy and Hardison, Ross C. and Burhans, Richard and Elnitski, Laura and Shah, Prachi and Zhang, Yi and Blankenberg, Daniel and Albert, Istvan and Taylor, James and Miller, Webb and Kent, W. James and Nekrutenko, Anton},
  year = {2005},
  month = oct,
  journal = {Genome Research},
  volume = {15},
  number = {10},
  pages = {1451--1455},
  issn = {1088-9051},
  doi = {10.1101/gr.4086505},
  abstract = {Accessing and analyzing the exponentially expanding genomic sequence and functional data pose a challenge for biomedical researchers. Here we describe an interactive system, Galaxy, that combines the power of existing genome annotation databases with a simple Web portal to enable users to search remote resources, combine data from independent queries, and visualize the results. The heart of Galaxy is a flexible history system that stores the queries from each user; performs operations such as intersections, unions, and subtractions; and links to other computational tools. Galaxy can be accessed at               http://g2.bx.psu.edu               .}
}

@article{afgan2018,
  title = {The {{Galaxy}} Platform for Accessible, Reproducible and Collaborative Biomedical Analyses: 2018 Update},
  shorttitle = {The {{Galaxy}} Platform for Accessible, Reproducible and Collaborative Biomedical Analyses},
  author = {Afgan, Enis and Baker, Dannon and Batut, B{\'e}r{\'e}nice and {van~den~Beek}, Marius and Bouvier, Dave and {\v C}ech, Martin and Chilton, John and Clements, Dave and Coraor, Nate and Gr{\"u}ning, Bj{\"o}rn A and Guerler, Aysam and {Hillman-Jackson}, Jennifer and Hiltemann, Saskia and Jalili, Vahid and Rasche, Helena and Soranzo, Nicola and Goecks, Jeremy and Taylor, James and Nekrutenko, Anton and Blankenberg, Daniel},
  year = {2018},
  month = jul,
  journal = {Nucleic Acids Research},
  volume = {46},
  number = {W1},
  pages = {W537-W544},
  issn = {0305-1048, 1362-4962},
  doi = {10.1093/nar/gky379},
  abstract = {Abstract Galaxy (homepage: https://galaxyproject.org, main public server: https://usegalaxy.org) is a web-based scientific analysis platform used by tens of thousands of scientists across the world to analyze large biomedical datasets such as those found in genomics, proteomics, metabolomics and imaging. Started in 2005, Galaxy continues to focus on three key challenges of data-driven biomedical science: making analyses accessible to all researchers, ensuring analyses are completely reproducible, and making it simple to communicate analyses so that they can be reused and extended. During the last two years, the Galaxy team and the open-source community around Galaxy have made substantial improvements to Galaxy's core framework, user interface, tools, and training materials. Framework and user interface improvements now enable Galaxy to be used for analyzing tens of thousands of datasets, and {$>$}5500 tools are now available from the Galaxy ToolShed. The Galaxy community has led an effort to create numerous high-quality tutorials focused on common types of genomic analyses. The Galaxy developer and user communities continue to grow and be integral to Galaxy's development. The number of Galaxy public servers, developers contributing to the Galaxy framework and its tools, and users of the main Galaxy server have all increased substantially.}
}

@article{koster2012,
  title = {Snakemake\textemdash a Scalable Bioinformatics Workflow Engine},
  author = {K{\"o}ster, Johannes and Rahmann, Sven},
  year = {2012},
  month = oct,
  journal = {Bioinformatics},
  volume = {28},
  number = {19},
  pages = {2520--2522},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/bts480},
  abstract = {Summary: Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames.Availability:http://snakemake.googlecode.com.Contact:johannes.koester@uni-due.de}
}

@article{ditommaso2017,
  title = {Nextflow Enables Reproducible Computational Workflows},
  author = {Di Tommaso, Paolo and Chatzou, Maria and Floden, Evan W and Barja, Pablo Prieto and Palumbo, Emilio and Notredame, Cedric},
  year = {2017},
  month = apr,
  journal = {Nature Biotechnology},
  volume = {35},
  number = {4},
  pages = {316--319},
  issn = {1087-0156, 1546-1696},
  doi = {10.1038/nbt.3820}
}

@article{wratten2021,
  title = {Reproducible, Scalable, and Shareable Analysis Pipelines with Bioinformatics Workflow Managers},
  author = {Wratten, L. and Wilm, A. and G{\"o}ke, J.},
  year = {2021},
  journal = {Nature methods},
  doi = {10.1038/s41592-021-01254-9},
  abstract = {This Perspective highlights key features of workflow managers, compares commonly used approaches for bioinformatics workflows, and provides a guide for computational and noncomputational users. The rapid growth of high-throughput technologies has transformed biomedical research. With the increasing amount and complexity of data, scalability and reproducibility have become essential not just for experiments, but also for computational analysis. However, transforming data into information involves running a large number of tools, optimizing parameters, and integrating dynamically changing reference data. Workflow managers were developed in response to such challenges. They simplify pipeline development, optimize resource usage, handle software installation and versions, and run on different compute platforms, enabling workflow portability and sharing. In this Perspective, we highlight key features of workflow managers, compare commonly used approaches for bioinformatics workflows, and provide a guide for computational and noncomputational users. We outline community-curated pipeline initiatives that enable novice and experienced users to perform complex, best-practice analyses without having to manually assemble workflows. In sum, we illustrate how workflow managers contribute to making computational analysis in biomedical research shareable, scalable, and reproducible.},
  creationdate = {2022-05-25T14:28:49}
}

@online{poholek2017,
  title = {Workflow {{Management Strategy Discussion}} with a {{Group}} of  25 {{Computational Biologists}} and {{Data Scientists}}},
  author = {Poholek, Amanda and Sun, Argus and Fang, Zhou and Rittenhouse, Natalie and Sethi, Rahil and Mallela, Ramya},
  year = {2017},
  url = {https://github.com/NCBI-Hackathons/SPeW#workflow-management-strategy-discussion-with-a-group-of-25-computational-biologists-and-data-scientists},
  urldate = {2022-05-17}
}

@inproceedings{larsonneur2018,
  title = {Evaluating {{Workflow Management Systems}}: {{A Bioinformatics Use Case}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Bioinformatics}} and {{Biomedicine}} ({{BIBM}})},
  author = {Larsonneur, Elise and Mercier, Jonathan and Wiart, Nicolas and Floch, Edith Le and Delhomme, Olivier and Meyer, Vincent},
  year = {2018},
  month = dec,
  publisher = {{IEEE}},
  doi = {10.1109/bibm.2018.8621141}
}

@article{jackson2021,
  title = {Using Prototyping to Choose a Bioinformatics Workflow Management System},
  author = {Jackson, Michael and Kavoussanakis, Kostas and Wallace, Edward W. J.},
  editor = {Ouellette, Francis},
  year = {2021},
  month = feb,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {2},
  pages = {e1008622},
  publisher = {{Public Library of Science (PLoS)}},
  doi = {10.1371/journal.pcbi.1008622}
}

@article{ewels2020,
  title = {The {nf-Core} Framework for Community-Curated Bioinformatics Pipelines},
  author = {Ewels, Philip A. and Peltzer, Alexander and Fillinger, Sven and Patel, Harshil and Alneberg, J. and Wilm, A. and Garcia, M. and Tommaso, Paolo Di and Nahnsen, S.},
  year = {2020},
  journal = {Nature Biotechnology},
  doi = {10.1038/s41587-020-0439-x},
  abstract = {The nf-core framework is introduced as a means for the development of collaborative, peerreviewed, best-practice analysis pipelines that can be used across all institutions and research facilities and introduces a higher degree of portability as compared to custom in-house scripts. To the Editor \textemdash{} The standardization, portability and reproducibility of analysis pipelines are key issues within the bioinformatics community. Most bioinformatics pipelines are designed for use on-premises; as a result, the associated software dependencies and execution logic are likely to be tightly coupled with proprietary computing environments. This can make it difficult or even impossible for others to reproduce the ensuing results, which is a fundamental requirement for the validation of scientific findings. Here, we introduce the nf-core framework as a means for the development of collaborative, peerreviewed, best-practice analysis pipelines (Fig. 1). All nf-core pipelines are written in Nextflow and so inherit the ability to be executed on most computational infrastructures, as well as having native support for container technologies such as Docker and Singularity. The nf-core community (Supplementary Fig. 1) has developed a suite of tools that automate pipeline creation, testing, deployment and synchronization. Our goal is to provide a framework for high-quality bioinformatics pipelines that can be used across all institutions and research facilities. Being able to reproduce scientific results is the central tenet of the scientific method. However, moving toward FAIR (findable, accessible, interoperable and reusable) research methods1 in data-driven science is complex2,3. Central repositories, such as bio. tools4, omictools5 and the Galaxy toolshed6, make it possible to find existing pipelines and their associated tools. However, it is still notoriously challenging to develop analysis pipelines that are fully reproducible and interoperable across multiple systems and institutions \textemdash{} primarily because of differences in hardware, operating systems and software versions. Although the recommended guidelines for some analysis pipelines have become standardized (for example, GATK best practices7), the actual implementations are usually developed on a case-by-case basis. As such, there is often little incentive to test, document and implement pipelines in a way that permits their reuse by other researchers. This can hamper sustainable sharing of data and tools, and results in a proliferation of heterogeneous analysis pipelines, making it difficult for newcomers to find what they need to address a specific analysis question. As the scale of -omics data and their associated analytical tools has grown, the scientific community is increasingly moving toward the use of specialized workflow management systems to build analysis pipelines8. They separate the requirements of the underlying compute infrastructure from the analysis and workflow description, introducing a higher degree of portability as compared to custom in-house scripts. One such popular tool is Nextflow9. Using Nextflow, software packages can be bundled with analysis pipelines using built-in integration for package managers, such as Conda, and containerization platforms, such as Docker and Singularity. Moreover, support for most common highperformance-computing batch schedulers and cloud providers allows simple deployment of analysis pipelines on almost any infrastructure. The opportunity to run pipelines locally during initial development and then to proceed seamlessly to largescale computational resources in highperformance-computing or cloud settings provides users and developers with great flexibility. The nf-core community project collects a curated set of best-practice analysis pipelines built using Nextflow. Similar projects Participate},
  creationdate = {2022-05-25T14:09:09}
}
@article{Zook2016,
  title = {Extensive Sequencing of Seven Human Genomes to Characterize Benchmark Reference Materials},
  author = {Zook, Justin M. and Catoe, David and McDaniel, Jennifer and Vang, Lindsay and Spies, Noah and Sidow, Arend and Weng, Ziming and Liu, Yuling and Mason, Christopher E. and Alexander, Noah and Henaff, Elizabeth and McIntyre, Alexa B. R. and Chandramohan, Dhruva and Chen, Feng and Jaeger, Erich and Moshrefi, Ali and Pham, Khoa and Stedman, William and Liang, Tiffany and Saghbini, Michael and Dzakula, Zeljko and Hastie, Alex and Cao, Han and Deikus, Gintaras and Schadt, Eric and Sebra, Robert and Bashir, Ali and Truty, Rebecca M. and Chang, Christopher C. and Gulbahce, Natali and Zhao, Keyan and Ghosh, Srinka and Hyland, Fiona and Fu, Yutao and Chaisson, Mark and Xiao, Chunlin and Trow, Jonathan and Sherry, Stephen T. and Zaranek, Alexander W. and Ball, Madeleine and Bobe, Jason and Estep, Preston and Church, George M. and Marks, Patrick and {Kyriazopoulou-Panagiotopoulou}, Sofia and Zheng, Grace X. Y. and {Schnall-Levin}, Michael and Ordonez, Heather S. and Mudivarti, Patrice A. and Giorda, Kristina and Sheng, Ying and Rypdal, Karoline Bjarnesdatter and Salit, Marc},
  year = {2016},
  month = jun,
  journal = {Scientific Data},
  volume = {3},
  number = {1},
  pages = {160025},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/sdata.2016.25},
  abstract = {The Genome in a Bottle Consortium, hosted by the National Institute of Standards and Technology (NIST) is creating reference materials and data for human genome sequencing, as well as methods for genome comparison and benchmarking. Here, we describe a large, diverse set of sequencing data for seven human genomes; five are current or candidate NIST Reference Materials. The pilot genome, NA12878, has been released as NIST RM 8398. We also describe data from two Personal Genome Project trios, one of Ashkenazim Jewish ancestry and one of Chinese ancestry. The data come from 12 technologies: BioNano Genomics, Complete Genomics paired-end and LFR, Ion Proton exome, Oxford Nanopore, Pacific Biosciences, SOLiD, 10X Genomics GemCode WGS, and Illumina exome and WGS paired-end, mate-pair, and synthetic long reads. Cell lines, DNA, and data from these individuals are publicly available. Therefore, we expect these data to be useful for revealing novel information about the human genome and improving sequencing technologies, SNP, indel, and structural variant calling, and de novo assembly.}
}
@article{Baid2020,
  title = {An {{Extensive Sequence Dataset}} of {{Gold-Standard Samples}} for {{Benchmarking}} and {{Development}}},
  author = {Baid, Gunjan and Nattestad, Maria and Kolesnikov, Alexey and Goel, Sidharth and Yang, Howard and Chang, Pi-Chuan and Carroll, Andrew},
  year = {2020},
  month = dec,
  pages = {2020.12.11.422022},
  publisher = {{bioRxiv}},
  doi = {10.1101/2020.12.11.422022},
  abstract = {Accurate standards and extensive development datasets are the foundation of technical progress. To facilitate benchmarking and development, we sequence 9 samples, covering the Genome in a Bottle truth sets on multiple instruments (NovaSeq, HiSeqX, HiSeq4000, PacBio Sequel II System) and sample preparations (PCR-Free, PCR-Positive) for both whole genome and multiple exome kits. We benchmark pipelines, quantifying strengths and limitations for sequencing and analysis methods. We identify variability within and between instruments, preparation methods, and analytical pipelines, across various sequencing depths. We discuss the relevance of this variability to downstream analyses, and strategies to reduce variability.},
  chapter = {New Results}
}
@article{Krusche2019,
  title = {Best Practices for Benchmarking Germline Small-Variant Calls in Human Genomes},
  author = {Krusche, Peter and Trigg, Len and Boutros, Paul C. and Mason, Christopher E. and De La Vega, Francisco M. and Moore, Benjamin L. and {Gonzalez-Porta}, Mar and Eberle, Michael A. and Tezak, Zivana and Lababidi, Samir and Truty, Rebecca and Asimenos, George and Funke, Birgit and Fleharty, Mark and Chapman, Brad A. and Salit, Marc and Zook, Justin M.},
  year = {2019},
  month = may,
  journal = {Nature Biotechnology},
  volume = {37},
  number = {5},
  pages = {555--560},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1696},
  doi = {10.1038/s41587-019-0054-x},
  abstract = {Standardized benchmarking approaches are required to assess the accuracy of variants called from sequence data. Although variant-calling tools and the metrics used to assess their performance continue to improve, important challenges remain. Here, as part of the Global Alliance for Genomics and Health (GA4GH), we present a benchmarking framework for variant calling. We provide guidance on how to match variant calls with different representations, define standard performance metrics, and stratify performance by variant type and genome context. We describe limitations of high-confidence calls and regions that can be used as truth sets (for example, single-nucleotide variant concordance of two methods is 99.7\% inside versus 76.5\% outside high-confidence regions). Our web-based app enables comparison of variant calls against truth sets to obtain a standardized performance report. Our approach has been piloted in the PrecisionFDA variant-calling challenges to identify the best-in-class variant-calling methods within high-confidence regions. Finally, we recommend a set of best practices for using our tools and evaluating the results.}
}
@article{Ahmed2021,
  title = {Design Considerations for Workflow Management Systems Use in Production Genomics Research and the Clinic},
  author = {Ahmed, Azza E. and Allen, Joshua M. and Bhat, Tajesvi and Burra, Prakruthi and Fliege, Christina E. and Hart, Steven N. and Heldenbrand, Jacob R. and Hudson, Matthew E. and Istanto, Dave Deandre and Kalmbach, Michael T. and Kapraun, Gregory D. and Kendig, Katherine I. and Kendzior, Matthew Charles and Klee, Eric W. and Mattson, Nate and Ross, Christian A. and Sharif, Sami M. and Venkatakrishnan, Ramshankar and Fadlelmola, Faisal M. and Mainzer, Liudmila S.},
  year = {2021},
  month = nov,
  journal = {Scientific Reports},
  volume = {11},
  number = {1},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1038/s41598-021-99288-8},
}
@online{IEEEAndTheOpenGroup2018,
  title = {The {{Open Group Base Specifications Issue}} 7 - Mkdir},
  author = {{IEEE and The Open Group}},
  year = {2018},
  url = {https://pubs.opengroup.org/onlinepubs/9699919799/utilities/mkdir.html},
  urldate = {2023-01-09}
}
@online{SeqeraLabs2022,
  title = {{{DSL}} 2 — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/dsl2.html},
  urldate = {2023-01-16}
}
@online{SeqeraLabs2022a,
  title = {Tracing \& Visualisation — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/tracing.html},
  urldate = {2023-01-17}
}
@article{Parnas1972,
  title = {On the Criteria to Be Used in Decomposing Systems into Modules},
  author = {Parnas, D. L.},
  date = {1972-12},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {15},
  number = {12},
  pages = {1053--1058},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/361598.361623},
  abstract = {This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a “modularization” is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched.}
}
@online{SeqeraLabs2022b,
  title = {Operators\#mix — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/operator.html#mix},
  urldate = {2023-01-19}
}

@online{SeqeraLabs2022c,
  title = {Containers\#{{Singularity}} — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/container.html#container-singularity},
  urldate = {2023-01-19}
}

@article{Sturm2016,
  title = {{{SeqPurge}}: Highly-Sensitive Adapter Trimming for Paired-End {{NGS}} Data},
  shorttitle = {{{SeqPurge}}},
  author = {Sturm, Marc and Schroeder, Christopher and Bauer, Peter},
  date = {2016-05-10},
  journaltitle = {BMC bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {17},
  eprint = {27161244},
  eprinttype = {pmid},
  pages = {208},
  issn = {1471-2105},
  doi = {10.1186/s12859-016-1069-7},
  abstract = {BACKGROUND: Trimming of adapter sequences from short read data is a common preprocessing step during NGS data analysis. When performing paired-end sequencing, the overlap between forward and reverse read can be used to identify excess adapter sequences. This is exploited by several previously published adapter trimming tools. However, our evaluation on amplicon-based data shows that most of the current tools are not able to remove all adapter sequences and that adapter contamination may even lead to spurious variant calls. RESULTS: Here we present SeqPurge ( https://github.com/imgag/ngs-bits ), a highly-sensitive adapter trimmer that uses a probabilistic approach to detect the overlap between forward and reverse reads of Illumina sequencing data. SeqPurge can detect very short adapter sequences, even if only one base long. Compared to other adapter trimmers specifically designed for paired-end data, we found that SeqPurge achieves a higher sensitivity. The number of remaining adapter bases after trimming is reduced by up to 90~\%, depending on the compared tool. In simulations with different error rates, we found that SeqPurge is also the most error-tolerant adapter trimmer in the comparison. CONCLUSION: SeqPurge achieves a very high sensitivity and a high error-tolerance, combined with a specificity and runtime that are comparable to other state-of-the-art adapter trimmers. The very good adapter trimming performance, complemented with additional features such as quality-based trimming and basic quality control, makes SeqPurge an excellent choice for the pre-processing of paired-end NGS data.},
  pmcid = {PMC4862148}
}

@online{SeqeraLabs2022d,
  title = {Metrics — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/metrics.html},
  urldate = {2023-01-31}
}

@online{AmazonWebServices2023,
  title = {{{AWS Pricing Calculator}}},
  author = {{Amazon Web Services}},
  date = {2023},
  url = {https://docs.aws.amazon.com/pricing-calculator/latest/userguide/what-is-pricing-calculator.html},
  urldate = {2023-02-01}
}

@online{MedizinischeHochschuleHannover2022,
  title = {Rapid Diagnosis Instead of a Long Odyssey},
  author = {{Medizinische Hochschule Hannover}},
  date = {2022-04-25},
  url = {https://www.mhh.de/en/presse/mhh-insight/news-detailed-view/rapid-diagnosis-instead-of-a-long-odyssey},
  urldate = {2023-02-02}
}

@article{Saunders2012,
  title = {Rapid {{Whole-Genome Sequencing}} for {{Genetic Disease Diagnosis}} in {{Neonatal Intensive Care Units}}},
  author = {Saunders, Carol Jean and Miller, Neil Andrew and Soden, Sarah Elizabeth and Dinwiddie, Darrell Lee and Noll, Aaron and Alnadi, Noor Abu and Andraws, Nevene and Patterson, Melanie LeAnn and Krivohlavek, Lisa Ann and Fellis, Joel and Humphray, Sean and Saffrey, Peter and Kingsbury, Zoya and Weir, Jacqueline Claire and Betley, Jason and Grocock, Russell James and Margulies, Elliott Harrison and Farrow, Emily Gwendolyn and Artman, Michael and Safina, Nicole Pauline and Petrikin, Joshua Erin and Hall, Kevin Peter and Kingsmore, Stephen Francis},
  date = {2012-10-03},
  journaltitle = {Science Translational Medicine},
  volume = {4},
  number = {154},
  pages = {154ra135-154ra135},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/scitranslmed.3004041},
  abstract = {Monogenic diseases are frequent causes of neonatal morbidity and mortality, and disease presentations are often undifferentiated at birth. More than 3500 monogenic diseases have been characterized, but clinical testing is available for only some of them and many feature clinical and genetic heterogeneity. Hence, an immense unmet need exists for improved molecular diagnosis in infants. Because disease progression is extremely rapid, albeit heterogeneous, in newborns, molecular diagnoses must occur quickly to be relevant for clinical decision-making. We describe 50-hour differential diagnosis of genetic disorders by whole-genome sequencing (WGS) that features automated bioinformatic analysis and is intended to be a prototype for use in neonatal intensive care units. Retrospective 50-hour WGS identified known molecular diagnoses in two children. Prospective WGS disclosed potential molecular diagnosis of a severe GJB2-related skin disease in one neonate; BRAT1-related lethal neonatal rigidity and multifocal seizure syndrome in another infant; identified BCL9L as a novel, recessive visceral heterotaxy gene (HTX6) in a pedigree; and ruled out known candidate genes in one infant. Sequencing of parents or affected siblings expedited the identification of disease genes in prospective cases. Thus, rapid WGS can potentially broaden and foreshorten differential diagnosis, resulting in fewer empirical treatments and faster progression to genetic and prognostic counseling.}
}

@online{SeqeraLabs2022e,
  title = {Configuration — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/config.html#},
  urldate = {2023-02-02}
}

@online{Seqeralabs2022f,
  title = {Processes — {{Nextflow}} 22.10.4 Documentation},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://www.nextflow.io/docs/latest/process.html},
  urldate = {2023-02-05}
}

@online{AmazonWebServices2023a,
  title = {{{AWS Marketplace}}: {{DRAGEN Complete Suite Pricing}}},
  shorttitle = {{{AWS Marketplace}}},
  author = {{Amazon Web Services}},
  date = {2023},
  url = {https://aws.amazon.com/marketplace/pp/prodview-ypz2tpzy6f5xq},
  urldate = {2023-02-05}
}

@online{AmazonWebServices2023b,
  title = {{{AWS Snowball Pricing}} | {{Amazon Web Services}}},
  author = {{Amazon Web Services}},
  url = {https://aws.amazon.com/snowball/pricing/},
  urldate = {2023-02-05}
}

@online{SeqeraLabs2022g,
  title = {Nextflow {{Tower}} - {{Introduction}}},
  author = {{Seqera Labs}},
  date = {2022},
  url = {https://help.tower.nf/22.3/},
  urldate = {2023-02-06}
}
